1. dataset.csv

mfcc_axis = 1
gfcc_axis = 1
bfcc_axis = 1
n_ceps = 16
sec_split = 0.8
freq = 44100
channels = 1
seed = 42
Power Scaler (Yao Johnson) per xgb, rf, ada
MinMax Scaler per Knn, svc, nn
Colonne Rimosse "gfcc_mean_0", "mfcc_mean_4", "mfcc_mean_5", "mfcc_mean_6", "mfcc_mean_8", "mfcc_mean_7"
clip outlier

Accuracy: 0.89
Precision: 0.86
Recall: 0.97

XGB Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}
Best RF Parameters: {'max_depth': None, 'n_estimators': 400}
Best KNN Parameters: {'n_neighbors': 9, 'p': 1, 'weights': 'distance'}


--------------------------------------------

2. dataset.csv

mfcc_axis = 1
gfcc_axis = 1
bfcc_axis = 1
n_ceps = 16
sec_split = 0.8
freq = 44100
channels = 1
seed = 42
Power Scaler (Yao Johnson) per xgb, rf, ada
MinMax Scaler per Knn, svc, nn
Colonne Rimosse "gfcc_mean_0", "mfcc_mean_4", "mfcc_mean_5", "mfcc_mean_6", "mfcc_mean_8", "mfcc_mean_7"
clip outlier

Best XGB Accuracy: 0.88
Best XGB Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.9}
----------TRAIN-----------
Accuracy: 0.97
Precision: 0.97
Recall: 0.98
------------------------------------
----------TEST-----------
Accuracy: 0.9
Precision: 0.9
Recall: 0.93
------------------------------------

Best RF Accuracy: 0.89
Best RF Parameters: {'max_depth': None, 'n_estimators': 300}
----------TRAIN-----------
Accuracy: 1.0
Precision: 1.0
Recall: 1.0
------------------------------------
----------TEST-----------
Accuracy: 0.92
Precision: 0.92
Recall: 0.94
------------------------------------

Best KNN Accuracy: 0.86
Best KNN Parameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}

----------TRAIN-----------
Accuracy: 1.0
Precision: 1.0
Recall: 1.0
------------------------------------
----------TEST-----------
Accuracy: 0.87
Precision: 0.9
Recall: 0.88
------------------------------------

Best ADA Accuracy: 0.77
Best ADA Parameters: {'learning_rate': 1.5, 'n_estimators': 200}
----------TRAIN-----------
Accuracy: 0.78
Precision: 0.79
Recall: 0.83
------------------------------------
----------TEST-----------
Accuracy: 0.77
Precision: 0.79
Recall: 0.82
------------------------------------

Best SVC Accuracy: 0.72
Best SVC Parameters: {'C': 2, 'kernel': 'rbf'}
----------TRAIN-----------
Accuracy: 0.73
Precision: 0.69
Recall: 0.94
------------------------------------
----------TEST-----------
Accuracy: 0.72
Precision: 0.7
Recall: 0.93
------------------------------------


def create_nn():
    tf.random.set_seed(seed)
    input_layer = layers.Input(shape=(X_train.shape[1],))
    x = layers.Dense(256)(input_layer)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Dense(128)(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Dense(32)(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    output_layer = layers.Dense(1, activation='sigmoid')(x)
    model = keras.Model(inputs=input_layer, outputs=output_layer)

    model.compile(optimizer=RMSprop(learning_rate=0.0005),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model


def train_nn(model):
    early_stopping = callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        verbose=1,
        restore_best_weights=True,
    )
    history = model.fit(X_train_nn, y_train, epochs=50, batch_size=256, validation_split=0.2,
                        callbacks=[early_stopping])
    return history

----------TRAIN-----------
Accuracy: 0.9
Precision: 0.91
Recall: 0.9
------------------------------------
----------TEST-----------
Accuracy: 0.85
Precision: 0.88
Recall: 0.86
------------------------------------

Ensemble
----------TRAIN-----------
Accuracy: 0.98
Precision: 0.97
Recall: 1.0
------------------------------------
----------TEST-----------
Accuracy: 0.9
Precision: 0.87
Recall: 0.97
------------------------------------
